"use client";

import { useEffect, useRef, useState } from "react";

export default function CameraCapture() {
  const videoRef = useRef(null); // Referência para o vídeo da câmera
  const canvasRef = useRef(null); // Referência para o canvas da câmera
  const resultCanvasRef = useRef(null); // Referência para o canvas de resultado
  const [isProcessing, setIsProcessing] = useState(false);
  const [opencvLoaded, setOpenCVLoaded] = useState(false);

  useEffect(() => {
    const loadOpenCV = async () => {
      try {
        // @ts-ignore 
        cv = await cv;
        setOpenCVLoaded(true);
      } catch (error) {
        console.error("Erro ao carregar OpenCV.js:", error);
      }
    };

    loadOpenCV();
    startCamera();

    return () => {
      stopCamera();
    };
  }, []);

  const startCamera = async () => {
    try {
      if (videoRef.current) {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "environment" },
        });

        // @ts-ignore 
        videoRef.current.srcObject = stream;
        // @ts-ignore 
        videoRef.current.play();
      }
    } catch (err) {
      console.error("Erro ao acessar a câmera:", err);
    }
  };

  const stopCamera = () => {
    // @ts-ignore 
    if (videoRef.current && videoRef.current.srcObject) {
      // @ts-ignore 
      const stream = videoRef.current.srcObject;
      // @ts-ignore 
      const tracks = stream.getTracks();
      // @ts-ignore 
      tracks.forEach((track) => track.stop());
      // @ts-ignore 
      videoRef.current.srcObject = null;
    }
  };

  const captureImage = () => {
    if (
      videoRef.current &&
      canvasRef.current &&
      resultCanvasRef.current &&
      opencvLoaded
    ) {
      // @ts-ignore 
      const video = videoRef.current;
      // @ts-ignore 
      const canvas = canvasRef.current;
      // @ts-ignore 
      const resultCanvas = resultCanvasRef.current;

      // @ts-ignore 
      canvas.width = video.videoWidth;
      // @ts-ignore 
      canvas.height = video.videoHeight;

      // @ts-ignore 
      const ctx = canvas.getContext("2d");
      // @ts-ignore 
      const resultCtx = resultCanvas.getContext("2d");

      // @ts-ignore 
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      processImage(canvas, resultCtx);
    }
  };

  // @ts-ignore 
  const processImage = (canvas, resultCtx) => {
    setIsProcessing(true);
    try {
      // @ts-ignore 
      let mat = cv.imread(canvas);
      // @ts-ignore 
      let gray = new cv.Mat();
      // @ts-ignore 
      let edges = new cv.Mat();
      // @ts-ignore 
      let contours = new cv.MatVector();
      // @ts-ignore 
      let hierarchy = new cv.Mat();

      // @ts-ignore 
      cv.cvtColor(mat, gray, cv.COLOR_RGBA2GRAY);
      // @ts-ignore 
      cv.Canny(gray, edges, 50, 150);
      // @ts-ignore 
      cv.findContours(edges, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);

      for (let i = 0; i < contours.size(); i++) {
        // @ts-ignore 
        let contour = contours.get(i);
        // @ts-ignore 
        let approx = new cv.Mat();
        // @ts-ignore 
        let epsilon = 0.02 * cv.arcLength(contour, true);
        // @ts-ignore 
        cv.approxPolyDP(contour, approx, epsilon, true);

        if (approx.rows === 4) {
          // @ts-ignore 
          const rect = cv.boundingRect(approx);
          // @ts-ignore 
          const roi = gray.roi(rect);
          // @ts-ignore 
          const mean = cv.mean(roi);
          // @ts-ignore 
          const isRasurado = mean[0] < 50; // Definir como "rasurado" se a média de intensidade for baixa

          // @ts-ignore 
          const color = isRasurado
          // @ts-ignore 
            ? new cv.Scalar(0, 255, 0) // Verde para quadrados rasurados
            // @ts-ignore 
            : new cv.Scalar(255, 0, 0); // Azul para quadrados normais

            // @ts-ignore 
          cv.drawContours(mat, contours, i, color, 2, cv.LINE_8, hierarchy, 0);

          roi.delete();
        }

        approx.delete();
      }

      // @ts-ignore 
      cv.imshow(resultCanvasRef.current, mat);

      mat.delete();
      gray.delete();
      edges.delete();
      contours.delete();
      hierarchy.delete();
    } catch (err) {
      console.error("Erro ao processar imagem:", err);
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <div>
      <h1>Captura da Câmera e Detecção de Quadrados</h1>

      <video
        ref={videoRef}
        width="640"
        height="480"
        style={{ border: "1px solid #000" }}
      />

      <canvas
        ref={canvasRef}
        width="640"
        height="480"
        style={{ display: "none" }}
      />

      <button onClick={captureImage} disabled={isProcessing || !opencvLoaded}>
        {isProcessing ? "Processando..." : "Capturar Imagem"}
      </button>

      <canvas
        ref={resultCanvasRef}
        width="640"
        height="480"
        style={{ border: "1px solid #000", marginTop: "20px" }}
      />

      {isProcessing && <p>Processando imagem...</p>}
      {!opencvLoaded && <p>Carregando OpenCV.js...</p>}
    </div>
  );
}
